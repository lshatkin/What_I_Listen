{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://janakiev.com/blog/jupyter-virtual-envs/\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "import copy\n",
    "import spotipy\n",
    "import pickle\n",
    "import json\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import math\n",
    "from datetime import timedelta, datetime\n",
    "from spotipy.oauth2 import SpotifyClientCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPOTIPY_CLIENT_ID=\"1af8231e16444a2eb708ce55225ea7bb\"\n",
    "SPOTIPY_CLIENT_SECRET=\"e3c233b23d1e42e4a4dba639b5913a9e\"\n",
    "sp = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(client_id = SPOTIPY_CLIENT_ID, \n",
    "                                                                         client_secret = SPOTIPY_CLIENT_SECRET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(_string):\n",
    "    \"\"\" Clean strings so they can be stored and retrieved. \"\"\"\n",
    "    try:\n",
    "        _string = _string.replace(\"'\", \"\")\n",
    "        _string = _string.replace('\"', \"\")\n",
    "    except:\n",
    "        print(_string)\n",
    "    return _string\n",
    "\n",
    "def clean_song_name(_string):\n",
    "    if \"feat\" in _string:\n",
    "        _string = _string.split(\"feat\",1)[0][:-1]\n",
    "    elif \"Feat\" in _string:\n",
    "        _string = _string.split(\"Feat\",1)[0][:-1]\n",
    "    return _string\n",
    "        \n",
    "def chance_the_rapper(x):\n",
    "    if x == \"CHANCE THE RAPPER\":\n",
    "        return \"Chance the Rapper\"\n",
    "    return x\n",
    "\n",
    "def load_data():\n",
    "    \"\"\" Load, clean and enrich data. \"\"\"\n",
    "    \n",
    "    # Load dataframes\n",
    "    data = pd.read_json(\"MyData/endsong_0.json\", convert_dates = ['ts'])\n",
    "    data1 = pd.read_json(\"MyData/endsong_1.json\", convert_dates = ['ts'])\n",
    "    data2 = pd.read_json(\"MyData/endsong_2.json\", convert_dates = ['ts'])\n",
    "    data = data.append(data1)\n",
    "    data = data.append(data2)\n",
    "    \n",
    "    # Get and rename relevant col names\n",
    "    data = data[['ts', 'master_metadata_track_name', 'master_metadata_album_artist_name','master_metadata_album_album_name']]\n",
    "    data = data.rename(columns = {\"ts\" : \"endTime\", \n",
    "                                  \"master_metadata_track_name\" : \"trackName\", \n",
    "                                  \"master_metadata_album_artist_name\" : \"artistName\",\n",
    "                                  \"master_metadata_album_album_name\" : \"albumName\"})\n",
    "    \n",
    "    # Clean and enrich data\n",
    "    data = data.dropna()\n",
    "    data['artistName'] = data['artistName'].apply(clean_string)\n",
    "    data['trackName'] = data['trackName'].apply(clean_string)\n",
    "    data['trackName'] = data['trackName'].apply(clean_song_name)\n",
    "    data['artistName'] = data.artistName.apply(chance_the_rapper)\n",
    "    \n",
    "    data = data[data.trackName != \"Love Is Everywhere (Beware)\"]\n",
    "    data = data[data.trackName != \"This American Life\"]\n",
    "    data = data.sort_values(by = \"endTime\")\n",
    "    \n",
    "    \n",
    "    data['count'] = 1\n",
    "    data['total_listens'] = data.groupby('artistName')['count'].transform(pd.Series.cumsum)\n",
    "    \n",
    "    \n",
    "    # Section off relevant data\n",
    "    artists = data.groupby(['artistName']).count()\n",
    "    relevant = artists[artists.endTime > 20].index\n",
    "    relevant_data = data.loc[data.artistName.isin(relevant)].sort_values(by = \"total_listens\")\n",
    "    \n",
    "    data = data.reset_index()\n",
    "    relevant_data = relevant_data.reset_index()\n",
    "    return data, relevant_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,relevant_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_artist(song_name, artist_name):\n",
    "    \"\"\" Get Artist Id using song and artist name.\n",
    "    \n",
    "    Searching only on artist name can provide faulty results,\n",
    "    such as Nas return Lil Nas X, or Whitney returning\n",
    "    Whitney Houston. Use a song as a secondary key, essentially.\n",
    "    \n",
    "    \"\"\"\n",
    "    results = sp.search(q='track:%s artist:%s'%(song_name, artist_name), type='track')\n",
    "    items = results['tracks']['items']\n",
    "    if len(items) > 0:\n",
    "        return items[0]['artists'][0]['id']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    \n",
    "def get_artist_genre(artist_id):\n",
    "    \"\"\" Return genre of an artist. \"\"\"\n",
    "    try:\n",
    "        artist_info = sp.artist(artist_id)\n",
    "        return artist_info['genres']\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_artist_id(data):\n",
    "    \"\"\" Accumulare and save mapping of artist to id.\n",
    "    \n",
    "    Spotify has an ID value for each artist that is needed\n",
    "    for further searching, i.e. looking up an artists genre.\n",
    "    Create and save this mapping because it is time\n",
    "    intensive with all the API calls.\n",
    "    \n",
    "    \"\"\"\n",
    "    artist_id_dic = {}\n",
    "    for index, row in data.iterrows():\n",
    "        artist_name = row['artistName']\n",
    "        if artist_name in artist_id_dic.keys():\n",
    "            continue\n",
    "        track_name = row['trackName']\n",
    "        artist_id = get_song_artist(track_name, artist_name)\n",
    "        if artist_id is not None:\n",
    "            artist_id_dic[artist_name] = artist_id\n",
    "    with open('artist_id.pickle', 'wb') as handle:\n",
    "        pickle.dump(artist_id_dic, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def save_genre_data(data, artist_id_dic):\n",
    "    \"\"\" Accumulate and save data about genres listened to.\n",
    "    \n",
    "    Create two dictionaries:\n",
    "        1) Map artist to their genres\n",
    "        2) Count how many artists per genre\n",
    "    \n",
    "    The second dictionary could be created after this, if\n",
    "    desired, but I just threw it in here as well.\n",
    "    \n",
    "    \"\"\"\n",
    "    genre_dic = {}\n",
    "    artist_genre_dic = {}\n",
    "    for artist_name in data.artistName.unique():\n",
    "        \n",
    "        # Some artists had no id found, so are not in\n",
    "        # the artist id lookup dictionary\n",
    "        if artist_name not in artist_id_dic:\n",
    "            continue\n",
    "        \n",
    "        genres = get_artist_genre(artist_id_dic[artist_name])\n",
    "        \n",
    "        # If there are no genres, still add to the dictionary\n",
    "        # to not cause errors later when looping through the \n",
    "        # keys.\n",
    "        if genres is None:\n",
    "            artist_genre_dic[artist_name] = None\n",
    "            continue\n",
    "        \n",
    "        artist_genre_dic[artist_name] = genres\n",
    "        for g in genres:\n",
    "            if g in genre_dic:\n",
    "                genre_dic[g] += 1\n",
    "            else:\n",
    "                genre_dic[g] = 1\n",
    "    with open('artist_genre.pickle', 'wb') as handle:\n",
    "        pickle.dump(artist_genre_dic, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('genre_dic.pickle', 'wb') as handle:\n",
    "        pickle.dump(genre_dic, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "def create_genre_to_artist_dic(artist_genres):\n",
    "    \"\"\" Create mapping of genre to all artist that classify as that genre.\n",
    "    \n",
    "    With a mapping created from genre to artist, it will be easy\n",
    "    to look at all the songs in a certain genre.\n",
    "    \n",
    "    \"\"\"\n",
    "    genres_to_artists = {}\n",
    "    artists_seen = set()\n",
    "    for artist, genres in artist_genres.items():\n",
    "        \n",
    "        # Don't want duplicate artists\n",
    "        if artist in artists_seen:\n",
    "            continue\n",
    "        \n",
    "        for g in genres:\n",
    "            if g in genres_to_artists:\n",
    "                genres_to_artists[g].append(artist)\n",
    "            else:\n",
    "                genres_to_artists[g] = [artist]\n",
    "        artists_seen.add(artist)\n",
    "    \n",
    "    return genres_to_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    file = open(\"artist_id.pickle\", \"rb\")\n",
    "    artist_id_dic = pickle.load(file)\n",
    "except:\n",
    "    save_artist_id(data)\n",
    "    \n",
    "\n",
    "try:\n",
    "    file = open(\"artist_genre.pickle\", \"rb\")\n",
    "    artist_genres = pickle.load(file)\n",
    "    file = open(\"genre_dic.pickle\", \"rb\")\n",
    "    genre_dic = pickle.load(file)\n",
    "except:\n",
    "    save_genre_data(data, artist_id_dic)\n",
    "\n",
    "genre_to_artist = create_genre_to_artist_dic(artist_genres)\n",
    "\n",
    "genres_df = pd.DataFrame.from_dict(genre_dic, orient = 'index', columns = ['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_of_day_helper(hour):\n",
    "    return (\n",
    "        \"morning\" if 3 <= hour <= 11\n",
    "        else\n",
    "        \"afternoon\" if 12 <= hour <= 17\n",
    "        else\n",
    "        \"evening\" if 18 <= hour <= 21\n",
    "        else\n",
    "        \"night\"\n",
    "    )\n",
    "\n",
    "def get_part_of_day(data):\n",
    "    data['part_of_day'] = data['endTime'].apply(lambda x: \n",
    "                                                get_part_of_day_helper(x.hour))\n",
    "\n",
    "def get_season_helper(month):\n",
    "    return (\n",
    "        \"spring\" if 4 <= month <= 5\n",
    "        else\n",
    "        \"summer\" if 6 <= month <= 8\n",
    "        else\n",
    "        \"fall\" if 9 <= month <= 10\n",
    "        else\n",
    "        \"winter\"\n",
    "    )\n",
    "\n",
    "def get_season(data):\n",
    "    data['season'] = data['endTime'].apply(lambda x: \n",
    "                                                get_season_helper(x.month))\n",
    "\n",
    "def get_day_of_week(data):\n",
    "    weekday_dic = {\n",
    "        0 : \"weekday\",\n",
    "        1 : \"weekday\",\n",
    "        2 : \"weekday\",\n",
    "        3 : \"weekday\",\n",
    "        4 : \"weekend\",\n",
    "        5 : \"weekend\",\n",
    "        6 : \"weekend\"\n",
    "    }\n",
    "    data['weekday'] = data['endTime'].apply(lambda x: weekday_dic[x.dayofweek])\n",
    "\n",
    "def get_year(data):\n",
    "    data['year'] = data['endTime'].apply(lambda x: str(x.year))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dic_helper(data_dic, row, cat_index, categories):\n",
    "    i = 0\n",
    "    curr_data = data_dic\n",
    "    while i < cat_index:\n",
    "        curr_data = curr_data[row[i]]\n",
    "        i += 1\n",
    "        \n",
    "    # BASE CASE\n",
    "    if cat_index == len(categories) - 1:\n",
    "        if row[cat_index] in curr_data.keys():\n",
    "            curr_data[row[cat_index]] += 1\n",
    "        else:\n",
    "            curr_data[row[cat_index]] = 1\n",
    "        return\n",
    "    \n",
    "    if row[cat_index] not in curr_data.keys():\n",
    "        curr_data[row[cat_index]] = {}\n",
    "    \n",
    "    return nested_dic_helper(data_dic, row, cat_index + 1, categories)\n",
    "\n",
    "\n",
    "def create_nested_dictionary(data, categories):\n",
    "    data_dic = {}\n",
    "    for _, row in data.iterrows():\n",
    "        data_of_cats = [row[cat] for cat in categories]\n",
    "        nested_dic_helper(data_dic, data_of_cats, 0, categories)\n",
    "    return data_dic\n",
    "\n",
    "\n",
    "def final_nest_helper(data_dic, level, num_cats):\n",
    "    if level == num_cats - 1:\n",
    "        return [{\"name\" : k, \"value\" : data_dic[k]} for k in data_dic.keys()]\n",
    "    return [{\"name\" : k, \"children\" : final_nest_helper(data_dic[k], level + 1, num_cats)\n",
    "                             } for k in data_dic.keys()]\n",
    "\n",
    "\n",
    "def create_final_nest(data_dic, categories):\n",
    "    final_dic = {\"name\" : \"songData\", \"children\" : []}\n",
    "    final_dic['children'] = final_nest_helper(data_dic, 0, len(categories))\n",
    "    return final_dic\n",
    "\n",
    "\n",
    "def create_category_heirarchy(data, categories):\n",
    "    nested_dictionary = create_nested_dictionary(data, categories) \n",
    "    final_nest = create_final_nest(nested_dictionary, categories)\n",
    "    return final_nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_songs_with_genre(data, artist_genres):\n",
    "    \"\"\" Same as top_artist_of_genre just with songs. \"\"\"\n",
    "    df = data\n",
    "    df['genres'] = df['artistName'].apply(lambda x : artist_genres[x] if x in artist_genres.keys() and artist_genres[x] else \"No Genre\")\n",
    "    df = df[df.genres != \"No Genre\"]\n",
    "    lst_col = 'genres'\n",
    "    r = pd.DataFrame({\n",
    "          col:np.repeat(df[col].values, df[lst_col].str.len())\n",
    "          for col in df.columns.drop(lst_col)}\n",
    "        ).assign(**{lst_col:np.concatenate(df[lst_col].values)})[df.columns]\n",
    "    r['total_listens_genre'] = r.groupby([\"genres\"])['count'].transform(pd.Series.cumsum)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_data(data):\n",
    "    \"\"\" Run enrichers on data. \"\"\"\n",
    "    enriched_data = data\n",
    "    get_part_of_day(enriched_data)\n",
    "    get_season(enriched_data)\n",
    "    get_day_of_week(enriched_data)\n",
    "    get_year(enriched_data)\n",
    "    return get_songs_with_genre(enriched_data, artist_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_hierarchy_data(data):\n",
    "    \"\"\" For each genre to be published, create time hierarchy dictionary.\n",
    "    \n",
    "    Unfortunately, I am skilled enough at D3 to be doing all \n",
    "    the parsing of the data within D3. So, I'll make a dictionary\n",
    "    for each individual genre, which can be loaded dynamically\n",
    "    when a genre is chosen.\n",
    "    \n",
    "    \"\"\"\n",
    "    enriched_data = enrich_data(data)\n",
    "    enriched_data.to_csv('enriched_song_data.csv')\n",
    "\n",
    "    # Get genres necessary for final output\n",
    "    genre_hi = create_genre_hierarchy(genres_df)\n",
    "    final = format_genre_hierarchy(genre_hi)\n",
    "    used_genres = set()\n",
    "    for d in final:\n",
    "        used_genres.add(d['id'].strip())\n",
    "\n",
    "    # Create time hierarchy for each genre\n",
    "    for genre in used_genres:\n",
    "        if genre != \"Genre\":\n",
    "            df = enriched_data[enriched_data.genres == genre]\n",
    "        else:\n",
    "            df = enriched_data\n",
    "        nest = create_category_heirarchy(df, ['year', 'season','weekday'])\n",
    "        stripped_genre = genre.replace(\" \", \"\").strip()\n",
    "        with open('time_hierarchy_data/%s.json' % stripped_genre, 'w') as outfile:\n",
    "            json.dump(nest, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_hierarchy_with_artist_data(data, categories = ['year', 'season','artistName','trackName'],\n",
    "                                          filename = 'time_hierarchy_with_artist_data'):\n",
    "    \"\"\" For each genre to be published, create time hierarchy dictionary.\n",
    "    \n",
    "    Unfortunately, I am skilled enough at D3 to be doing all \n",
    "    the parsing of the data within D3. So, I'll make a dictionary\n",
    "    for each individual genre, which can be loaded dynamically\n",
    "    when a genre is chosen.\n",
    "    \n",
    "    \"\"\"\n",
    "    enriched_data = enrich_data(data)\n",
    "    enriched_data.to_csv('enriched_song_data.csv')\n",
    "\n",
    "    # Get genres necessary for final output\n",
    "    genre_hi = create_genre_hierarchy(genres_df)\n",
    "    final = format_genre_hierarchy(genre_hi)\n",
    "    used_genres = set()\n",
    "    for d in final:\n",
    "        used_genres.add(d['id'].strip())\n",
    "\n",
    "    # Create time hierarchy for each genre\n",
    "    for genre in used_genres:\n",
    "        if genre != \"Genre\":\n",
    "            df = enriched_data[enriched_data.genres == genre]\n",
    "        else:\n",
    "            df = enriched_data\n",
    "        nest = create_category_heirarchy(df, categories)\n",
    "        stripped_genre = genre.replace(\" \", \"\").strip()\n",
    "        with open(filename + ('/%s.json' % stripped_genre), 'w') as outfile:\n",
    "            json.dump(nest, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_time_hierarchy_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_time_hierarchy_with_artist_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_time_hierarchy_with_artist_data(data, ['artistName', 'trackName'], 'artist_hierarchy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_genre_hierarchy(genres_df):\n",
    "    ''' Create hierarchy as genres based on names of genres. \n",
    "    \n",
    "    The hierarchy created in this function is solely based on title. So,\n",
    "    if the word of one genre, 'Rock', exists in another genre, 'Indie Rock'\n",
    "    or 'Alternative Rock' or 'Classic Rock', then 'Rock' becomes the parent\n",
    "    to those genres. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Load the DF and add some more features\n",
    "    genre_hierarchy_df = genres_df\n",
    "    genre_hierarchy_df['genre'] = genre_hierarchy_df.index\n",
    "    genre_hierarchy_df['num_words_genre'] = genre_hierarchy_df['genre'].apply(lambda x: \n",
    "                                                    len(x.split()))\n",
    "    genre_hierarchy_df['num_chars_genre'] = genre_hierarchy_df['genre'].apply(lambda x: \n",
    "                                                    len(x))\n",
    "    longest_genre = max(genre_hierarchy_df['num_words_genre'])\n",
    "\n",
    "    # Initialize dictionary\n",
    "    nested_genres = {}\n",
    "\n",
    "    # Want to loop backwards to start with bottom layer\n",
    "    # and then add genres on top of that. For example, start\n",
    "    # with Modern Alternative Rock then make that a child of\n",
    "    # Alternative Rock then make that a child of Rock\n",
    "    for genre_length in range(longest_genre, 0, -1):\n",
    "        \n",
    "        df = genre_hierarchy_df[genre_hierarchy_df.num_words_genre == genre_length]\n",
    "        df = df.sort_values(by = 'num_chars_genre')\n",
    "        \n",
    "        # Loop through each genre\n",
    "        for genre, count in zip(df['genre'], df['count']):\n",
    "            \n",
    "            nested = False\n",
    "            \n",
    "            # Look at the already existing genres, so these will be\n",
    "            # the longer genres that have already been added\n",
    "            for k in list(nested_genres.keys()):\n",
    "                \n",
    "                # If the current genre is a subet of one of the \n",
    "                # already existing. For example, \"rock\" in \n",
    "                # \"alternative rock\". If this happens, we want\n",
    "                # to create a chlid parent relationship\n",
    "                if genre in k:\n",
    "                    \n",
    "                    # If k-value genre, aka the potential child,\n",
    "                    # is a sub-genre and the only child of its\n",
    "                    # parent, then delete. Otherwise, every genre\n",
    "                    # would have a child of itself, which looks messy.\n",
    "                    if \"sub\" in k:\n",
    "                        parent = nested_genres[k]['parent']\n",
    "                        if nested_genres[parent]['num_child'] == 1:\n",
    "                            del nested_genres[k]\n",
    "                            nested_genres[parent]['num_child'] -= 1\n",
    "                            continue\n",
    "                    \n",
    "                    \n",
    "                    # If the potential child already has a parent,\n",
    "                    # then move on. This is so \"Modern Alternative\n",
    "                    # Rock\" stays with the parent \"Alternative Rock\",\n",
    "                    # rather than getting overridden by \"Rock\".\n",
    "                    if nested_genres[k]['parent'] != \"Genre\":\n",
    "                        continue\n",
    "                    \n",
    "                    # If the genre that is about to become a parent\n",
    "                    # does not already exist, then initialize. \n",
    "                    if not nested:\n",
    "                        nested_genres[genre] = {\"id\" : genre, \"value\" : int(count), \"parent\" : \"Genre\", \n",
    "                                                    \"num_child\" : 0}\n",
    "\n",
    "                    # Set the parent appropriately and update\n",
    "                    # the parents total value and children. \n",
    "                    nested_genres[k]['parent'] = genre\n",
    "                    nested_genres[genre]['num_child'] += 1\n",
    "                    nested_genres[genre]['value'] += nested_genres[k]['value']\n",
    "                    nested = True\n",
    "            \n",
    "            # If the genre did not become a parent to any genre,\n",
    "            # then initialize the genre with the generic parent of\n",
    "            # 'Genre'. \n",
    "            if not nested:\n",
    "                nested_genres[genre] = {\"id\" : genre, \"value\" : int(count), \"parent\" : \"Genre\", \"num_child\" : 0}\n",
    "            \n",
    "            # And the genre itself as a child of itself. Alter the\n",
    "            # key and id so no duplicates.\n",
    "            nested_genres[\"sub_\" + genre] = {\"id\" : genre + \" \", \"value\" : int(count), \n",
    "                                                     \"parent\" : genre, \"num_child\" : 0}\n",
    "            nested_genres[genre]['num_child'] += 1\n",
    "                \n",
    "    return nested_genres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_genre_hierarchy(genre_hi, delete_prop = 0.01):\n",
    "    \"\"\" Format genre hierarchy for D3 use.\n",
    "    \n",
    "    In order to the use the hierarchy - created in\n",
    "    \"create_genre_hierarchy\" - in D3, the data must \n",
    "    be molded into a specific format. Also, this function\n",
    "    prunes out irrelevant genres, as defined by \n",
    "    making up less than 1% of its parent genre.\n",
    "    \"\"\"\n",
    "\n",
    "    final = []\n",
    "    \n",
    "    # Make copy so original values are stored.\n",
    "    value_dic = copy.deepcopy(genre_hi)\n",
    "\n",
    "    parents_added = set()\n",
    "    parents_deleted = set()\n",
    "    \n",
    "    # Adds the root, needed for D3.\n",
    "    final.append({\"id\" : \"Genre\"})\n",
    "    parents_added.add(\"Genre\")\n",
    "    \n",
    "    # Computes the total of everything, as the\n",
    "    # genres with parent of Genre have the counts\n",
    "    # of all its children.\n",
    "    genre_count = 0\n",
    "    for k in genre_hi.keys():\n",
    "        if genre_hi[k]['parent'] == \"Genre\":\n",
    "            genre_count += genre_hi[k]['value']\n",
    "    \n",
    "    # Keys will be deleted once added to the final\n",
    "    # list.\n",
    "    while len(genre_hi.keys()) > 0:\n",
    "        for k in list(genre_hi.keys()):\n",
    "            \n",
    "            parent = genre_hi[k]['parent']\n",
    "            \n",
    "            # Pruning: If the genre does not make up more than 1%\n",
    "            # of its parent's total, then prune.\n",
    "            total = genre_count if parent == \"Genre\" else value_dic[parent]['value']\n",
    "            if float(value_dic[k]['value']) / total < delete_prop:\n",
    "                parents_deleted.add(k)\n",
    "                del genre_hi[k]\n",
    "                continue\n",
    "            \n",
    "            # Only children should have values, otherwise D3 double\n",
    "            # counts the children and the parent values.\n",
    "            if genre_hi[k]['num_child'] > 0:\n",
    "                genre_hi[k]['value'] = 0\n",
    "\n",
    "            # If parent is deleted, then child deleted too.\n",
    "            if parent in parents_deleted:\n",
    "                parents_deleted.add(k)\n",
    "                del genre_hi[k]\n",
    "                continue\n",
    "            \n",
    "            # If parent is added, then child added too.\n",
    "            if parent in parents_added:\n",
    "                final.append(genre_hi[k])\n",
    "                parents_added.add(k)\n",
    "                del genre_hi[k]\n",
    "\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_hi = create_genre_hierarchy(genres_df)\n",
    "final_df = pd.DataFrame(format_genre_hierarchy(genre_hi))\n",
    "final_df.to_csv(\"genre_hierarchy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_artists_of_genre(data, artist_genres):\n",
    "    \"\"\" Get all time listens and genres for each artist.\n",
    "    \n",
    "    As of now, get all time listens. This may have to change\n",
    "    if an adjustable timeline is added. Need a df with keys\n",
    "    artistName and genre for querying in d3.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Only take the max number of listens, which will be\n",
    "    # the total number of listens at the end of time\n",
    "    top_artists = data.groupby(['artistName'])['total_listens'].max()\n",
    "    df = pd.DataFrame(top_artists)\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns = {\"level_0\" : \"artist\"})\n",
    "    \n",
    "    # Get genre data from the artist genres dictionary.\n",
    "    df['genres'] = df['artistName'].apply(lambda x : artist_genres[x] if x in artist_genres.keys() and artist_genres[x] else \"No Genre\")\n",
    "    df = df[df.genres != \"No Genre\"]\n",
    "    \n",
    "    # Expand list of genres so each genre get \n",
    "    # its own row with the artist\n",
    "    lst_col = 'genres'\n",
    "    r = pd.DataFrame({\n",
    "          col:np.repeat(df[col].values, df[lst_col].str.len())\n",
    "          for col in df.columns.drop(lst_col)}\n",
    "        ).assign(**{lst_col:np.concatenate(df[lst_col].values)})[df.columns]\n",
    "    \n",
    "    # Sort and save\n",
    "    r = r.sort_values(by = 'total_listens', ascending = False)\n",
    "    r.to_csv(\"total_listens_artist.csv\")\n",
    "    no_dups = r.drop_duplicates(['artistName'])\n",
    "    no_dups.to_csv(\"total_listens_artist_all_genres.csv\")\n",
    "\n",
    "def top_songs_of_genre(data, artist_genres):\n",
    "    \"\"\" Same as top_artist_of_genre just with songs. \"\"\"\n",
    "    \n",
    "    data['total_listens_track'] = data.groupby(['trackName','artistName'])['count'].transform(pd.Series.cumsum)\n",
    "\n",
    "    top_songs = data.groupby(['trackName','artistName'])['total_listens_track'].max()\n",
    "    df = pd.DataFrame(top_songs)\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns = {\"level_0\" : \"artist\"})\n",
    "\n",
    "    df['genres'] = df['artistName'].apply(lambda x : artist_genres[x] if x in artist_genres.keys() and artist_genres[x] else \"No Genre\")\n",
    "    df = df[df.genres != \"No Genre\"]\n",
    "\n",
    "    lst_col = 'genres'\n",
    "    r = pd.DataFrame({\n",
    "          col:np.repeat(df[col].values, df[lst_col].str.len())\n",
    "          for col in df.columns.drop(lst_col)}\n",
    "        ).assign(**{lst_col:np.concatenate(df[lst_col].values)})[df.columns]\n",
    "    r = r.sort_values(by = 'total_listens_track', ascending = False)\n",
    "    r.to_csv(\"total_listens_track.csv\")\n",
    "    no_dups = r.drop_duplicates(['trackName','artistName'])\n",
    "    no_dups.to_csv(\"total_listens_track_all_genres.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_artists_of_genre(data, artist_genres)\n",
    "top_songs_of_genre(data, artist_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_time_period(df, dic, start, end):\n",
    "    \"\"\" Get listening history between given dates. \"\"\"\n",
    "    \n",
    "    df = df.loc[df['endTime'] <= end]\n",
    "    df = df.loc[df['endTime'] >= start]\n",
    "    \n",
    "    # Get the total number of listens up to this point in time\n",
    "    # (meaning listens from beginning of time until current date)\n",
    "    idx = df.groupby(['artistName'])['total_listens'].transform(max) == df['total_listens']\n",
    "    dic[end] = df[idx][['artistName', 'total_listens']]\n",
    "    \n",
    "\n",
    "def get_time_periods_dfs(data, _weeks = 2):\n",
    "    \"\"\" Fill dictioanry mapping dates to time period dataframes. \n",
    "    \n",
    "    A time period dataframe is created by the fill_time_period\n",
    "    function and holds the total listens for each artist up\n",
    "    to the end of that time period.\n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    time_period_data = {}\n",
    "    final_end_date = data.iloc[-1]['endTime']\n",
    "    \n",
    "    # If there is not enough data, do not loop\n",
    "    total_weeks = (final_end_date - data.iloc[0]['endTime']).days / 7\n",
    "    if total_weeks < _weeks:\n",
    "        fill_time_period(data, time_period_data, data.iloc[0]['endTime'], final_end_date)\n",
    "        return time_period_data\n",
    "        \n",
    "    # Start input weeks into the future and look back\n",
    "    # when gather data\n",
    "    date = data.iloc[0]['endTime']  + timedelta(weeks = _weeks)\n",
    "    while date <= final_end_date:\n",
    "        time_period_data[date] = None\n",
    "        start_date = date - timedelta(weeks = _weeks)\n",
    "        fill_time_period(data, time_period_data, start_date, date)\n",
    "        date += timedelta(weeks = _weeks)\n",
    "    \n",
    "    return time_period_data\n",
    "\n",
    "def artist_level_data(data, time_period_data):\n",
    "    \"\"\" Create timeseries data for each artist. \n",
    "    \n",
    "    For every artist, create a dataframe that holds\n",
    "    the total listens up to given dates, where the dates\n",
    "    are every few weeks (depends on _weeks parameter of\n",
    "    get_time_periods_dfs) from the beginning of time until\n",
    "    the end.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    artist_data = {}\n",
    "    artist_count = 0\n",
    "    for artist in list(data.artistName.unique()):\n",
    "        \n",
    "        # Initialize Variables\n",
    "        artist_data[artist] = {}\n",
    "        first_date = True\n",
    "        week_counter = 1\n",
    "        \n",
    "        for date, total in time_period_data.items():\n",
    "            artist_data[artist][date] = {}\n",
    "                        \n",
    "            # Get the current total listens up to this time frame\n",
    "            artist_sum = total[total.artistName == artist]\n",
    "            if len(artist_sum.index) == 0:\n",
    "                artist_data[artist][date][\"sum\"] = 0 if first_date else artist_data[artist][prev_date][\"sum\"]\n",
    "            else:\n",
    "                artist_data[artist][date][\"sum\"] = artist_sum['total_listens'].iloc[0]\n",
    "            \n",
    "            # Reset Variables\n",
    "            artist_data[artist][date]['week'] = week_counter\n",
    "            prev_date = date\n",
    "            week_counter += 1\n",
    "            if first_date:\n",
    "                first_date = False\n",
    "    \n",
    "    # Reformate data \n",
    "    df = pd.DataFrame.from_dict({(i, j): artist_data[i][j]\n",
    "            for i in artist_data.keys()\n",
    "            for j in artist_data[i].keys()},\n",
    "            orient = 'index')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_songs_with_genre_simple(data, artist_genres):\n",
    "    \"\"\" Add genre to every song in listening history. \"\"\"\n",
    "    \n",
    "    # Add list of genres to every song\n",
    "    df = data\n",
    "    df['genres'] = df['artistName'].apply(lambda x : artist_genres[x] if x in artist_genres.keys() and artist_genres[x] else \"No Genre\")\n",
    "    df = df[df.genres != \"No Genre\"]\n",
    "    \n",
    "    # Mutate so every song has a row for each of its\n",
    "    # genres.\n",
    "    lst_col = 'genres'\n",
    "    r = pd.DataFrame({\n",
    "          col:np.repeat(df[col].values, df[lst_col].str.len())\n",
    "          for col in df.columns.drop(lst_col)}\n",
    "        ).assign(**{lst_col:np.concatenate(df[lst_col].values)})[df.columns]\n",
    "    r['total_listens_genre'] = r.groupby([\"genres\"])['count'].transform(pd.Series.cumsum)\n",
    "    return r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_with_genre = get_songs_with_genre_simple(data, artist_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_genre_artist_timeline(data, artist_genres):\n",
    "    \"\"\" For each genre to be published, create time hierarchy dictionary.\n",
    "    \n",
    "    Unfortunately, I am skilled enough at D3 to be doing all \n",
    "    the parsing of the data within D3. So, I'll make a dictionary\n",
    "    for each individual genre, which can be loaded dynamically\n",
    "    when a genre is chosen.\n",
    "    \n",
    "    \"\"\"\n",
    "    songs_with_genre = get_songs_with_genre_simple(data, artist_genres)\n",
    "\n",
    "    # Get genres necessary for final output\n",
    "    genre_hi = create_genre_hierarchy(genres_df)\n",
    "    final = format_genre_hierarchy(genre_hi)\n",
    "    used_genres = set()\n",
    "    for d in final:\n",
    "        used_genres.add(d['id'].strip())\n",
    "\n",
    "    # Create time hierarchy for each genre\n",
    "    genre_count = 0\n",
    "    for genre in tqdm(used_genres):\n",
    "\n",
    "        if genre == \"Genre\":\n",
    "            df = songs_with_genre\n",
    "        else:\n",
    "            df = songs_with_genre[songs_with_genre.genres == genre]\n",
    "            \n",
    "        # Only look at the top 10 artists\n",
    "        artists = df.groupby(['artistName']).count()\n",
    "        relevant = artists.sort_values(by = 'count', ascending = False).iloc[0:10].index\n",
    "        relevant_data = df.loc[df.artistName.isin(relevant)].sort_values(by = \"total_listens\")\n",
    "        \n",
    "        # Fill a timeline dataset\n",
    "        artist_over_time = artist_level_data(relevant_data, get_time_periods_dfs(relevant_data))\n",
    "        \n",
    "        # Reorganize and take select columns\n",
    "        df = artist_over_time\n",
    "        df = df.reset_index()\n",
    "        df = df.rename(columns = {\"level_0\" : \"artist\", \"level_1\" : \"endTime\"})\n",
    "        df['date'] = df['endTime'].apply(lambda x : str(x.date()))\n",
    "        df = df[['artist','sum','date']]\n",
    "        \n",
    "        # Mutate for D3 acceptable format\n",
    "        newf = df.pivot(index='artist', columns='date')\n",
    "        newf.columns = newf.columns.droplevel(0)\n",
    "        newf.to_csv(\"artist_over_time/%s.csv\" % genre)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_genre_artist_timeline(data, artist_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_race_data(data, artist_genres):\n",
    "    songs_with_genre = get_songs_with_genre(data, artist_genres)\n",
    "\n",
    "    # Get genres necessary for final output\n",
    "    genre_hi = create_genre_hierarchy(genres_df)\n",
    "    final = format_genre_hierarchy(genre_hi)\n",
    "    used_genres = set()\n",
    "    for d in final:\n",
    "        used_genres.add(d['id'].strip())\n",
    "\n",
    "    # Create time hierarchy for each genre\n",
    "    genre_count = 0\n",
    "    for genre in tqdm(used_genres):\n",
    "        \n",
    "        if genre == \"Genre\":\n",
    "            df = songs_with_genre\n",
    "        else:\n",
    "            df = songs_with_genre[songs_with_genre.genres == genre]\n",
    "        \n",
    "        # Fill a timeline dataset\n",
    "        artist_over_time = artist_level_data(df, get_time_periods_dfs(df))\n",
    "        \n",
    "        # Reorganize and take select columns\n",
    "        df = artist_over_time\n",
    "        df = df.reset_index()\n",
    "        df = df.rename(columns = {\"level_0\" : \"artist\", \"level_1\" : \"endTime\"})\n",
    "        df['date'] = df['endTime'].apply(lambda x : str(x.date()))\n",
    "        df.to_csv(\"bar_race_data/%s.csv\" % genre.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [13:44<00:00,  4.19s/it]  \n"
     ]
    }
   ],
   "source": [
    "create_bar_race_data(data, artist_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dependency_graph(df):\n",
    "\n",
    "#     df = data\n",
    "    df['genres'] = df['artistName'].apply(lambda x : artist_genres[x] if x in artist_genres.keys() and artist_genres[x] else \"No Genre\")\n",
    "    df = df[df.genres != \"No Genre\"]\n",
    "    df = df.drop_duplicates('artistName')\n",
    "\n",
    "    genre_dependency_dic = {}\n",
    "\n",
    "    genre_hi = create_genre_hierarchy(genres_df)\n",
    "    final = format_genre_hierarchy(genre_hi, 0.01)\n",
    "    used_genres = set()\n",
    "    for d in final:\n",
    "        used_genres.add(d['id'].strip())\n",
    "\n",
    "    genre_hi = create_genre_hierarchy(genres_df)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        genres = row['genres']\n",
    "        artistName = row['artistName'].replace(\" \", \"\")\n",
    "\n",
    "        for g in genres:\n",
    "\n",
    "            # Only want to look at genres that are published\n",
    "            if g not in used_genres:\n",
    "                continue\n",
    "\n",
    "            parent = genre_hi[g]['parent']\n",
    "            if parent != 'Genre':\n",
    "                continue\n",
    "\n",
    "\n",
    "            if g not in genre_dependency_dic:\n",
    "                name = \"genre.\" + parent + \".\" + g \n",
    "                genre_dependency_dic[g] = {\"name\" : name,\n",
    "                                             \"imports\" : []}\n",
    "\n",
    "            for g_ in genres:\n",
    "                if g_ not in used_genres:\n",
    "                    continue\n",
    "\n",
    "                parent = genre_hi[g_]['parent']\n",
    "                if parent != 'Genre':\n",
    "                    continue\n",
    "\n",
    "                name = \"genre.\" + parent + \".\" + g_ \n",
    "                genre_dependency_dic[g][\"imports\"].append(name)\n",
    "\n",
    "    dependency_graph = []\n",
    "    for v in genre_dependency_dic.values():\n",
    "        dependency_graph.append(v)\n",
    "    \n",
    "    return dependency_graph\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_graph = create_dependency_graph(data)\n",
    "with open('dependency_graph.json', 'w') as outfile:\n",
    "            json.dump(dependency_graph, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotify_env",
   "language": "python",
   "name": "spotify_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
